{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Natural Language Processing Using NLTK (I)</center>\n",
    "\n",
    "References:\n",
    " - http://www.nltk.org/book_1ed/\n",
    " - https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    " - https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n",
    " - http://textminingonline.com/dive-into-nltk-part-iv-stemming-and-lemmatization\n",
    " - https://web.stanford.edu/class/cs124/lec/Information_Extraction_and_Named_Entity_Recognition.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NLTK installation\n",
    " 1. Install NLTK package using: pip install nltk \n",
    " 2. Open your python editor (Jupyter Notebook, Spyder etc.) and type the following comands below. Select \"all packages\" to install data included in NLTK, including corpora and books. It may take a few minutes to download all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NLP Objectives and Basic Steps\n",
    "\n",
    " - Objectives:\n",
    "   * Split documents into tokens or segments\n",
    "   * Clean up tokens and annotate tokens\n",
    "   * Extract features from tokens for further text mining tasks\n",
    " - Basic processing steps:\n",
    "   * Tokenization: split documents into individual words or segments\n",
    "   * Remove stop words and filter tokens\n",
    "   * POS (part of speech) Tagging\n",
    "   * Normalization: Stemming, Lemmatization\n",
    "   * Named Entity Recognition (NER)\n",
    "   * Term Frequency and Inverse Dcoument Frequency (TF-IDF)\n",
    "   * Create document-to-term matrix (bag of words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import re    # import re module\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small example for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"`strange days' chronicles the last two days of 1999 in los angeles. \\n as the locals gear up for the new millenium , lenny nero (ralph fiennes) goes about his business of peddling erotic memory clips. \\n he pines for his ex-girlfriend, faith (juliette lewis), but doesn't notice that another friend, mace (angela bassett) really cares for him. \\n this film features good performances, impressive film-making technique and breath-taking crowd scenes. \\n director kathryn bigelow knows her stuff and does not hesitate to use it. \\n but as a whole, this is an unsatisfying movie. \\n the problem is that the writers, james cameron and jay cocks , were too ambitious, aiming for a film with social relevance, thrills, and drama. \\n not that ambitious film-making should be discouraged; just that when it fails to achieve its goals, it fails badly and obviously. \\n the film just ends up preachy, unexciting and uninvolving.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 2.1. Load the text for analysis\n",
    "\n",
    "text='''`strange days' chronicles the last two days of 1999 in los angeles. \n",
    " as the locals gear up for the new millenium , lenny nero (ralph fiennes) goes about his business of peddling erotic memory clips. \n",
    " he pines for his ex-girlfriend, faith (juliette lewis), but doesn't notice that another friend, mace (angela bassett) really cares for him. \n",
    " this film features good performances, impressive film-making technique and breath-taking crowd scenes. \n",
    " director kathryn bigelow knows her stuff and does not hesitate to use it. \n",
    " but as a whole, this is an unsatisfying movie. \n",
    " the problem is that the writers, james cameron and jay cocks , were too ambitious, aiming for a film with social relevance, thrills, and drama. \n",
    " not that ambitious film-making should be discouraged; just that when it fails to achieve its goals, it fails badly and obviously. \n",
    " the film just ends up preachy, unexciting and uninvolving.'''\n",
    "\n",
    "text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Tokenization\n",
    " - **Definition**: the process of breaking a stream of textual content up into words, terms, symbols, or some other meaningful elements called tokens.\n",
    "    * Word (Unigram)\n",
    "    * Bigram (Two consecutive words)\n",
    "    * Trigram (Three consecutive words)\n",
    "    * Sentence\n",
    " - Different methods exist:\n",
    "    * Split by regular expression patterns\n",
    "    * NLTK's word tokenizer\n",
    "    * NLTK's regular expression tokenizer (customizable)\n",
    " - None of them can be perfect for any tokenization task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### method 1: split by regular expression patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "['', 'strange', 'days', 'chronicles', 'the', 'last', 'two', 'days', 'of', '1999', 'in', 'los', 'angeles', 'as', 'the', 'locals', 'gear', 'up', 'for', 'the', 'new', 'millenium', 'lenny', 'nero', 'ralph', 'fiennes', 'goes', 'about', 'his', 'business', 'of', 'peddling', 'erotic', 'memory', 'clips', 'he', 'pines', 'for', 'his', 'ex', 'girlfriend', 'faith', 'juliette', 'lewis', 'but', 'doesn', 't', 'notice', 'that', 'another', 'friend', 'mace', 'angela', 'bassett', 'really', 'cares', 'for', 'him', 'this', 'film', 'features', 'good', 'performances', 'impressive', 'film', 'making', 'technique', 'and', 'breath', 'taking', 'crowd', 'scenes', 'director', 'kathryn', 'bigelow', 'knows', 'her', 'stuff', 'and', 'does', 'not', 'hesitate', 'to', 'use', 'it', 'but', 'as', 'a', 'whole', 'this', 'is', 'an', 'unsatisfying', 'movie', 'the', 'problem', 'is', 'that', 'the', 'writers', 'james', 'cameron', 'and', 'jay', 'cocks', 'were', 'too', 'ambitious', 'aiming', 'for', 'a', 'film', 'with', 'social', 'relevance', 'thrills', 'and', 'drama', 'not', 'that', 'ambitious', 'film', 'making', 'should', 'be', 'discouraged', 'just', 'that', 'when', 'it', 'fails', 'to', 'achieve', 'its', 'goals', 'it', 'fails', 'badly', 'and', 'obviously', 'the', 'film', 'just', 'ends', 'up', 'preachy', 'unexciting', 'and', 'uninvolving', '']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1.1. Simply split the text by one or more non-word characters\n",
    "\n",
    "# \\W+: one or more non-words\n",
    "tokens1 = re.split(r\"\\W+\", text)   ## method: split by regular expression.\n",
    "\n",
    "# get the number of tokens\n",
    "\n",
    "print(len(tokens1))                   \n",
    "print(tokens1)                     \n",
    "\n",
    "#优缺点：\n",
    "# Pros: no punctuation, just words\n",
    "# Cons: breath-taking and film-making, doesn't are split into two words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### method 2: split by NLTK's word toeknizer\n",
    "\n",
    "- nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "['`strange', 'days', \"'\", 'chronicles', 'the', 'last', 'two', 'days', 'of', '1999', 'in', 'los', 'angeles', '.', 'as', 'the', 'locals', 'gear', 'up', 'for', 'the', 'new', 'millenium', ',', 'lenny', 'nero', '(', 'ralph', 'fiennes', ')', 'goes', 'about', 'his', 'business', 'of', 'peddling', 'erotic', 'memory', 'clips', '.', 'he', 'pines', 'for', 'his', 'ex-girlfriend', ',', 'faith', '(', 'juliette', 'lewis', ')', ',', 'but', 'does', \"n't\", 'notice', 'that', 'another', 'friend', ',', 'mace', '(', 'angela', 'bassett', ')', 'really', 'cares', 'for', 'him', '.', 'this', 'film', 'features', 'good', 'performances', ',', 'impressive', 'film-making', 'technique', 'and', 'breath-taking', 'crowd', 'scenes', '.', 'director', 'kathryn', 'bigelow', 'knows', 'her', 'stuff', 'and', 'does', 'not', 'hesitate', 'to', 'use', 'it', '.', 'but', 'as', 'a', 'whole', ',', 'this', 'is', 'an', 'unsatisfying', 'movie', '.', 'the', 'problem', 'is', 'that', 'the', 'writers', ',', 'james', 'cameron', 'and', 'jay', 'cocks', ',', 'were', 'too', 'ambitious', ',', 'aiming', 'for', 'a', 'film', 'with', 'social', 'relevance', ',', 'thrills', ',', 'and', 'drama', '.', 'not', 'that', 'ambitious', 'film-making', 'should', 'be', 'discouraged', ';', 'just', 'that', 'when', 'it', 'fails', 'to', 'achieve', 'its', 'goals', ',', 'it', 'fails', 'badly', 'and', 'obviously', '.', 'the', 'film', 'just', 'ends', 'up', 'preachy', ',', 'unexciting', 'and', 'uninvolving', '.']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1.2 NLTK's word tokenizer: \n",
    "\n",
    "# break down text into words and punctuations\n",
    "\n",
    "# invoke NLTK's word tokenizer\n",
    "tokens2 = nltk.word_tokenize(text)    \n",
    "print(len(tokens2) )                   \n",
    "print (tokens2)       \n",
    "\n",
    "# Pros: words are well tokenized, e.g. breath-taking and film-making each is captured as one word\n",
    "# doesn't becomes does n't\n",
    "# Cons: need to remove punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  自带的\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### after tokenizing text, text will be split into a list word plus punctuations. \n",
    "- goal: remove punctuation\n",
    "- how:\n",
    "    - strip(): remove punctuation\n",
    "    - remove empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strange',\n",
       " 'days',\n",
       " '',\n",
       " 'chronicles',\n",
       " 'the',\n",
       " 'last',\n",
       " 'two',\n",
       " 'days',\n",
       " 'of',\n",
       " '1999',\n",
       " 'in',\n",
       " 'los',\n",
       " 'angeles',\n",
       " '',\n",
       " 'as',\n",
       " 'the',\n",
       " 'locals',\n",
       " 'gear',\n",
       " 'up',\n",
       " 'for',\n",
       " 'the',\n",
       " 'new',\n",
       " 'millenium',\n",
       " '',\n",
       " 'lenny',\n",
       " 'nero',\n",
       " '',\n",
       " 'ralph',\n",
       " 'fiennes',\n",
       " '',\n",
       " 'goes',\n",
       " 'about',\n",
       " 'his',\n",
       " 'business',\n",
       " 'of',\n",
       " 'peddling',\n",
       " 'erotic',\n",
       " 'memory',\n",
       " 'clips',\n",
       " '',\n",
       " 'he',\n",
       " 'pines',\n",
       " 'for',\n",
       " 'his',\n",
       " 'ex-girlfriend',\n",
       " '',\n",
       " 'faith',\n",
       " '',\n",
       " 'juliette',\n",
       " 'lewis',\n",
       " '',\n",
       " '',\n",
       " 'but',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'notice',\n",
       " 'that',\n",
       " 'another',\n",
       " 'friend',\n",
       " '',\n",
       " 'mace',\n",
       " '',\n",
       " 'angela',\n",
       " 'bassett',\n",
       " '',\n",
       " 'really',\n",
       " 'cares',\n",
       " 'for',\n",
       " 'him',\n",
       " '',\n",
       " 'this',\n",
       " 'film',\n",
       " 'features',\n",
       " 'good',\n",
       " 'performances',\n",
       " '',\n",
       " 'impressive',\n",
       " 'film-making',\n",
       " 'technique',\n",
       " 'and',\n",
       " 'breath-taking',\n",
       " 'crowd',\n",
       " 'scenes',\n",
       " '',\n",
       " 'director',\n",
       " 'kathryn',\n",
       " 'bigelow',\n",
       " 'knows',\n",
       " 'her',\n",
       " 'stuff',\n",
       " 'and',\n",
       " 'does',\n",
       " 'not',\n",
       " 'hesitate',\n",
       " 'to',\n",
       " 'use',\n",
       " 'it',\n",
       " '',\n",
       " 'but',\n",
       " 'as',\n",
       " 'a',\n",
       " 'whole',\n",
       " '',\n",
       " 'this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'unsatisfying',\n",
       " 'movie',\n",
       " '',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'writers',\n",
       " '',\n",
       " 'james',\n",
       " 'cameron',\n",
       " 'and',\n",
       " 'jay',\n",
       " 'cocks',\n",
       " '',\n",
       " 'were',\n",
       " 'too',\n",
       " 'ambitious',\n",
       " '',\n",
       " 'aiming',\n",
       " 'for',\n",
       " 'a',\n",
       " 'film',\n",
       " 'with',\n",
       " 'social',\n",
       " 'relevance',\n",
       " '',\n",
       " 'thrills',\n",
       " '',\n",
       " 'and',\n",
       " 'drama',\n",
       " '',\n",
       " 'not',\n",
       " 'that',\n",
       " 'ambitious',\n",
       " 'film-making',\n",
       " 'should',\n",
       " 'be',\n",
       " 'discouraged',\n",
       " '',\n",
       " 'just',\n",
       " 'that',\n",
       " 'when',\n",
       " 'it',\n",
       " 'fails',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'its',\n",
       " 'goals',\n",
       " '',\n",
       " 'it',\n",
       " 'fails',\n",
       " 'badly',\n",
       " 'and',\n",
       " 'obviously',\n",
       " '',\n",
       " 'the',\n",
       " 'film',\n",
       " 'just',\n",
       " 'ends',\n",
       " 'up',\n",
       " 'preachy',\n",
       " '',\n",
       " 'unexciting',\n",
       " 'and',\n",
       " 'uninvolving',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove leading or trailing punctuations\n",
    "## an approach to removing punctuations\n",
    "## strip()\n",
    "tokens=[token.strip(string.punctuation) for token in tokens2]\n",
    "## result: punctuations are removed but empty tokens are left\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['statistics', '', ' ', '']\n",
      "['statistics', ',', '', '']\n"
     ]
    }
   ],
   "source": [
    "test = [\"statistics\",\",\",\" \",\"\"]\n",
    "test1 = [word.strip(\",\") for word in test] ## strip(\",\"): remove \",\"\n",
    "print(test1)\n",
    "test2 = [word.strip() for word in test] ## strip(): remove space\n",
    "print(test2)\n",
    "\n",
    "## empty string: for empty string, strip() result will be space.\n",
    "## \"statistic\" string : for this string, strip() result will be itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "['strange', 'days', 'chronicles', 'the', 'last', 'two', 'days', 'of', '1999', 'in', 'los', 'angeles', 'as', 'the', 'locals', 'gear', 'up', 'for', 'the', 'new', 'millenium', 'lenny', 'nero', 'ralph', 'fiennes', 'goes', 'about', 'his', 'business', 'of', 'peddling', 'erotic', 'memory', 'clips', 'he', 'pines', 'for', 'his', 'ex-girlfriend', 'faith', 'juliette', 'lewis', 'but', 'does', \"n't\", 'notice', 'that', 'another', 'friend', 'mace', 'angela', 'bassett', 'really', 'cares', 'for', 'him', 'this', 'film', 'features', 'good', 'performances', 'impressive', 'film-making', 'technique', 'and', 'breath-taking', 'crowd', 'scenes', 'director', 'kathryn', 'bigelow', 'knows', 'her', 'stuff', 'and', 'does', 'not', 'hesitate', 'to', 'use', 'it', 'but', 'as', 'a', 'whole', 'this', 'is', 'an', 'unsatisfying', 'movie', 'the', 'problem', 'is', 'that', 'the', 'writers', 'james', 'cameron', 'and', 'jay', 'cocks', 'were', 'too', 'ambitious', 'aiming', 'for', 'a', 'film', 'with', 'social', 'relevance', 'thrills', 'and', 'drama', 'not', 'that', 'ambitious', 'film-making', 'should', 'be', 'discouraged', 'just', 'that', 'when', 'it', 'fails', 'to', 'achieve', 'its', 'goals', 'it', 'fails', 'badly', 'and', 'obviously', 'the', 'film', 'just', 'ends', 'up', 'preachy', 'unexciting', 'and', 'uninvolving']\n"
     ]
    }
   ],
   "source": [
    "# remove empty tokens\n",
    "tokens=[token.strip() for token in tokens if token.strip()!='']\n",
    "print(len(tokens) )\n",
    "print(tokens)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### method3: NLTK's regular expression tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "['strange', 'days', 'chronicles', 'the', 'last', 'two', 'days', 'of', '1999', 'in', 'los', 'angeles', 'as', 'the', 'locals', 'gear', 'up', 'for', 'the', 'new', 'millenium', 'lenny', 'nero', 'ralph', 'fiennes', 'goes', 'about', 'his', 'business', 'of', 'peddling', 'erotic', 'memory', 'clips', 'he', 'pines', 'for', 'his', 'ex-girlfriend', 'faith', 'juliette', 'lewis', 'but', \"doesn't\", 'notice', 'that', 'another', 'friend', 'mace', 'angela', 'bassett', 'really', 'cares', 'for', 'him', 'this', 'film', 'features', 'good', 'performances', 'impressive', 'film-making', 'technique', 'and', 'breath-taking', 'crowd', 'scenes', 'director', 'kathryn', 'bigelow', 'knows', 'her', 'stuff', 'and', 'does', 'not', 'hesitate', 'to', 'use', 'it', 'but', 'as', 'whole', 'this', 'is', 'an', 'unsatisfying', 'movie', 'the', 'problem', 'is', 'that', 'the', 'writers', 'james', 'cameron', 'and', 'jay', 'cocks', 'were', 'too', 'ambitious', 'aiming', 'for', 'film', 'with', 'social', 'relevance', 'thrills', 'and', 'drama', 'not', 'that', 'ambitious', 'film-making', 'should', 'be', 'discouraged', 'just', 'that', 'when', 'it', 'fails', 'to', 'achieve', 'its', 'goals', 'it', 'fails', 'badly', 'and', 'obviously', 'the', 'film', 'just', 'ends', 'up', 'preachy', 'unexciting', 'and', 'uninvolving']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1.2 NLTK's regular expression tokenizer (customizable)\n",
    "\n",
    "# Pattern can be customized to your need\n",
    "\n",
    "# a word is defined as a sequence of word characters  \n",
    "# followed by optional word characters or \"-|'\" \n",
    "# ended with a word character\n",
    "\n",
    "# e.g. film-making, doesn't\n",
    "\n",
    "pattern=r'\\w[\\w\\-\\']*\\w'                        \n",
    "\n",
    "\n",
    "# call NLTK's regular expression tokenization\n",
    "tokens=nltk.regexp_tokenize(text, pattern)\n",
    "\n",
    "print(len(tokens))\n",
    "print (tokens)\n",
    "\n",
    "## keep \"\"film-making\", didn't split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[\"`strange days' chronicles the last two days of 1999 in los angeles.\", 'as the locals gear up for the new millenium , lenny nero (ralph fiennes) goes about his business of peddling erotic memory clips.', \"he pines for his ex-girlfriend, faith (juliette lewis), but doesn't notice that another friend, mace (angela bassett) really cares for him.\", 'this film features good performances, impressive film-making technique and breath-taking crowd scenes.', 'director kathryn bigelow knows her stuff and does not hesitate to use it.', 'but as a whole, this is an unsatisfying movie.', 'the problem is that the writers, james cameron and jay cocks , were too ambitious, aiming for a film with social relevance, thrills, and drama.', 'not that ambitious film-making should be discouraged; just that when it fails to achieve its goals, it fails badly and obviously.', 'the film just ends up preachy, unexciting and uninvolving.']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1.3 Use NLTK's regular expression tokenizer \n",
    "# to define sentences (i.e. starts with non-space character, \n",
    "# ends with !?.)\n",
    "\n",
    "pattern = r'\\S[^!?.]*[!?.]'\n",
    "\n",
    "sentences = nltk.regexp_tokenize(text,pattern)\n",
    "\n",
    "\n",
    "print(len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.2. Vocabulary \n",
    " - Vocabulary: the set of unique tokens  \n",
    " - Dictionary: typicallly, the vocabulary of a text can be represented as a dictionary \n",
    "    * Key: word\n",
    "    * Value: count of the word\n",
    " - Find what words are frequently used (stop words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the occurrence of each word in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lewis', 'kathryn', 'an', 'whole', 'ambitious', 'good', 'social', 'for', 'los', 'really', 'that', 'movie', 'obviously', 'locals', 'strange', 'badly', 'fiennes', 'features', 'peddling', 'preachy', 'were', 'two', 'memory', 'millenium', 'clips', 'the', 'new', 'film', 'stuff', 'ex-girlfriend', 'his', 'erotic', 'scenes', 'relevance', 'this', 'her', 'breath-taking', 'problem', 'its', 'he', 'technique', 'cocks', 'business', 'crowd', 'unexciting', 'does', 'thrills', 'impressive', 'faith', 'goes', 'too', 'but', 'writers', 'use', 'mace', 'him', 'film-making', 'angeles', 'james', 'bigelow', 'performances', 'jay', 'hesitate', 'uninvolving', 'last', 'angela', 'aiming', 'just', 'up', 'ralph', 'it', 'ends', '1999', 'cares', 'days', 'notice', 'not', 'bassett', 'achieve', 'goals', 'nero', 'in', 'cameron', 'with', 'discouraged', 'when', 'and', 'pines', 'gear', 'drama', 'friend', 'juliette', 'be', 'knows', 'as', \"doesn't\", 'about', 'unsatisfying', 'of', 'fails', 'director', 'is', 'another', 'should', 'chronicles', 'to', 'lenny'}\n",
      "\n",
      "sort by word\n",
      "{'lewis': 1, 'kathryn': 1, 'an': 1, 'whole': 1, 'ambitious': 2, 'good': 1, 'social': 1, 'for': 4, 'los': 1, 'really': 1, 'that': 4, 'movie': 1, 'obviously': 1, 'locals': 1, 'strange': 1, 'badly': 1, 'fiennes': 1, 'features': 1, 'peddling': 1, 'preachy': 1, 'were': 1, 'two': 1, 'memory': 1, 'millenium': 1, 'clips': 1, 'the': 6, 'new': 1, 'film': 3, 'stuff': 1, 'ex-girlfriend': 1, 'his': 2, 'erotic': 1, 'scenes': 1, 'relevance': 1, 'this': 2, 'her': 1, 'breath-taking': 1, 'problem': 1, 'its': 1, 'he': 1, 'technique': 1, 'cocks': 1, 'business': 1, 'crowd': 1, 'unexciting': 1, 'does': 1, 'thrills': 1, 'impressive': 1, 'faith': 1, 'goes': 1, 'too': 1, 'but': 2, 'writers': 1, 'use': 1, 'mace': 1, 'him': 1, 'film-making': 2, 'angeles': 1, 'james': 1, 'bigelow': 1, 'performances': 1, 'jay': 1, 'hesitate': 1, 'uninvolving': 1, 'last': 1, 'angela': 1, 'aiming': 1, 'just': 2, 'up': 2, 'ralph': 1, 'it': 3, 'ends': 1, '1999': 1, 'cares': 1, 'days': 2, 'notice': 1, 'not': 2, 'bassett': 1, 'achieve': 1, 'goals': 1, 'nero': 1, 'in': 1, 'cameron': 1, 'with': 1, 'discouraged': 1, 'when': 1, 'and': 6, 'pines': 1, 'gear': 1, 'drama': 1, 'friend': 1, 'juliette': 1, 'be': 1, 'knows': 1, 'as': 2, \"doesn't\": 1, 'about': 1, 'unsatisfying': 1, 'of': 2, 'fails': 2, 'director': 1, 'is': 2, 'another': 1, 'should': 1, 'chronicles': 1, 'to': 2, 'lenny': 1}\n",
      "\n",
      "sort by frequency\n",
      "[('the', 6), ('and', 6), ('for', 4), ('that', 4), ('film', 3), ('it', 3), ('ambitious', 2), ('his', 2), ('this', 2), ('but', 2), ('film-making', 2), ('just', 2), ('up', 2), ('days', 2), ('not', 2), ('as', 2), ('of', 2), ('fails', 2), ('is', 2), ('to', 2), ('lewis', 1), ('kathryn', 1), ('an', 1), ('whole', 1), ('good', 1), ('social', 1), ('los', 1), ('really', 1), ('movie', 1), ('obviously', 1), ('locals', 1), ('strange', 1), ('badly', 1), ('fiennes', 1), ('features', 1), ('peddling', 1), ('preachy', 1), ('were', 1), ('two', 1), ('memory', 1), ('millenium', 1), ('clips', 1), ('new', 1), ('stuff', 1), ('ex-girlfriend', 1), ('erotic', 1), ('scenes', 1), ('relevance', 1), ('her', 1), ('breath-taking', 1), ('problem', 1), ('its', 1), ('he', 1), ('technique', 1), ('cocks', 1), ('business', 1), ('crowd', 1), ('unexciting', 1), ('does', 1), ('thrills', 1), ('impressive', 1), ('faith', 1), ('goes', 1), ('too', 1), ('writers', 1), ('use', 1), ('mace', 1), ('him', 1), ('angeles', 1), ('james', 1), ('bigelow', 1), ('performances', 1), ('jay', 1), ('hesitate', 1), ('uninvolving', 1), ('last', 1), ('angela', 1), ('aiming', 1), ('ralph', 1), ('ends', 1), ('1999', 1), ('cares', 1), ('notice', 1), ('bassett', 1), ('achieve', 1), ('goals', 1), ('nero', 1), ('in', 1), ('cameron', 1), ('with', 1), ('discouraged', 1), ('when', 1), ('pines', 1), ('gear', 1), ('drama', 1), ('friend', 1), ('juliette', 1), ('be', 1), ('knows', 1), (\"doesn't\", 1), ('about', 1), ('unsatisfying', 1), ('director', 1), ('another', 1), ('should', 1), ('chronicles', 1), ('lenny', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.2.1 \n",
    "# Get vocabulary and dictionary of text\n",
    "\n",
    "vocabulary= set(tokens)                                        \n",
    "# set() convert a list to a set without any duplicates\n",
    "print (vocabulary)\n",
    "\n",
    "# tokens.count(word) returns the count of the word in tokens (list)\n",
    "dictionary={word: tokens.count(word) for word in vocabulary}\n",
    "# by default, dictionary is sorted by key\n",
    "print(\"\\nsort by word\")\n",
    "print (dictionary)\n",
    "\n",
    "# find what are the frequent words\n",
    "# sort the dictionary by value\n",
    "# sorted(iterable, key) sorts an iterable object by the comparison key\n",
    "# lambda: anonymous function defined without a name. \n",
    "# lambda item:-item[1] sorts the list by the 2nd element in a descending order\n",
    "print(\"\\nsort by frequency\")\n",
    "print(sorted(dictionary.items(), key=lambda item:-item[1]))\n",
    "\n",
    "# what kind of words usually have high frequency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.3. Stop words and word filtering\n",
    "\n",
    " - Stop words: a set of commonly used words, have very little meaning, and cannot differentiate a text from others, such as \"and\", \"the\" etc. \n",
    " - Stop words are typically ignored in NLP processing or by search engine\n",
    " - Stop words usually are application specific. You can define your own stop words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'film', 'films']\n",
      "\n",
      "sort dictionary without stop words by frequency\n",
      "[('ambitious', 2), ('film-making', 2), ('days', 2), ('fails', 2), ('lewis', 1), ('kathryn', 1), ('whole', 1), ('good', 1), ('social', 1), ('los', 1), ('really', 1), ('movie', 1), ('obviously', 1), ('locals', 1), ('strange', 1), ('badly', 1), ('fiennes', 1), ('features', 1), ('peddling', 1), ('preachy', 1), ('two', 1), ('memory', 1), ('millenium', 1), ('clips', 1), ('new', 1), ('stuff', 1), ('ex-girlfriend', 1), ('erotic', 1), ('scenes', 1), ('relevance', 1), ('breath-taking', 1), ('problem', 1), ('technique', 1), ('cocks', 1), ('business', 1), ('crowd', 1), ('unexciting', 1), ('thrills', 1), ('impressive', 1), ('faith', 1), ('goes', 1), ('writers', 1), ('use', 1), ('mace', 1), ('angeles', 1), ('james', 1), ('bigelow', 1), ('performances', 1), ('jay', 1), ('hesitate', 1), ('uninvolving', 1), ('last', 1), ('angela', 1), ('aiming', 1), ('ralph', 1), ('ends', 1), ('1999', 1), ('cares', 1), ('notice', 1), ('bassett', 1), ('achieve', 1), ('goals', 1), ('nero', 1), ('cameron', 1), ('discouraged', 1), ('pines', 1), ('gear', 1), ('drama', 1), ('friend', 1), ('juliette', 1), ('knows', 1), ('unsatisfying', 1), ('director', 1), ('another', 1), ('chronicles', 1), ('lenny', 1)]\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.3.1\n",
    "# get NLTK English stop words\n",
    "# You can modify this list by adding more stop words or remove stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words+=[\"film\", \"films\"]\n",
    "print (stop_words)\n",
    "\n",
    "# filter stop words out of the dictionary by creating a new dictionary\n",
    "\n",
    "filtered_dictionary={word: dictionary[word] \\\n",
    "                     for word in dictionary \\\n",
    "                     if word not in stop_words}\n",
    "print(\"\\nsort dictionary without stop words by frequency\")\n",
    "print(sorted(filtered_dictionary.items(), key=lambda item:-item[1]))\n",
    "\n",
    "print(len(filtered_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从词库中匹配positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faith', 'good', 'impressive', 'ambitious', 'thrills', 'ambitious']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.3.2\n",
    "# Find positive words \n",
    "\n",
    "with open(\"positive-words.txt\",'r') as f:\n",
    "    positive_words=[line.strip() for line in f]\n",
    "\n",
    "#print(positive_words)\n",
    "positive_tokens=[token for token in tokens \\\n",
    "                 if token in positive_words]\n",
    "\n",
    "print(positive_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Can you use positive/negative words to determine the sentiment?\n",
    "\n",
    "- Naive sentiment analysis:\n",
    "  - Find positive/negative words\n",
    "  - If more positive words than negative, then positive\n",
    "  - Otherwise, negative\n",
    "- Note the sentence: \n",
    "  -  \"the problem is that the writers, james cameron and jay cocks , were **<font color=\"red\">too ambitious</font>**, aiming for a film with social relevance, thrills, and drama. **<font color=\"red\">not that ambitious</font>** film-making should be discouraged; just that when it fails to achieve its goals, it fails badly and obviously. the film just ends up preachy, unexciting and uninvolving.\"\n",
    "- How to deal with negation?\n",
    "- Some useful rules:\n",
    "    - Negative sentiment: \n",
    "      - negative words not preceded by a negation within $n$ (e.g. three) words in the same sentence.\n",
    "      - positive words preceded by a negation within $n$ (e.g. three) words in the same sentence.\n",
    "    - Positive sentiment (in the similar fashion):\n",
    "      - positive words not preceded by a negation within $n$ (e.g. three) words in the same sentence.\n",
    "      - negative terms following a negation within  $n$ (e.g. three) words in the same sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['`strange', 'days', \"'\", 'chronicles', 'the', 'last', 'two', 'days', 'of', '1999', 'in', 'los', 'angeles', '.', 'as', 'the', 'locals', 'gear', 'up', 'for', 'the', 'new', 'millenium', ',', 'lenny', 'nero', '(', 'ralph', 'fiennes', ')', 'goes', 'about', 'his', 'business', 'of', 'peddling', 'erotic', 'memory', 'clips', '.', 'he', 'pines', 'for', 'his', 'ex-girlfriend', ',', 'faith', '(', 'juliette', 'lewis', ')', ',', 'but', 'does', \"n't\", 'notice', 'that', 'another', 'friend', ',', 'mace', '(', 'angela', 'bassett', ')', 'really', 'cares', 'for', 'him', '.', 'this', 'film', 'features', 'good', 'performances', ',', 'impressive', 'film-making', 'technique', 'and', 'breath-taking', 'crowd', 'scenes', '.', 'director', 'kathryn', 'bigelow', 'knows', 'her', 'stuff', 'and', 'does', 'not', 'hesitate', 'to', 'use', 'it', '.', 'but', 'as', 'a', 'whole', ',', 'this', 'is', 'an', 'unsatisfying', 'movie', '.', 'the', 'problem', 'is', 'that', 'the', 'writers', ',', 'james', 'cameron', 'and', 'jay', 'cocks', ',', 'were', 'too', 'ambitious', ',', 'aiming', 'for', 'a', 'film', 'with', 'social', 'relevance', ',', 'thrills', ',', 'and', 'drama', '.', 'not', 'that', 'ambitious', 'film-making', 'should', 'be', 'discouraged', ';', 'just', 'that', 'when', 'it', 'fails', 'to', 'achieve', 'its', 'goals', ',', 'it', 'fails', 'badly', 'and', 'obviously', '.', 'the', 'film', 'just', 'ends', 'up', 'preachy', ',', 'unexciting', 'and', 'uninvolving', '.']\n",
      "['faith', 'good', 'impressive', 'thrills', 'ambitious']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.3.1 # check if a positive word is preceded by negation words\n",
    "# e.g. not, too, n't, no, cannot\n",
    "\n",
    "negations=['not', 'too', 'n\\'t', 'no', 'cannot', 'neither','nor']\n",
    "tokens = nltk.word_tokenize(text)  \n",
    "\n",
    "print(tokens)\n",
    "\n",
    "positive_tokens=[]\n",
    "for idx, token in enumerate(tokens):\n",
    "    if token in positive_words:\n",
    "        if idx>0:\n",
    "            if tokens[idx-1] not in negations:\n",
    "                positive_tokens.append(token)\n",
    "        else:\n",
    "            positive_tokens.append(token)\n",
    "\n",
    "\n",
    "print(positive_tokens)\n",
    "\n",
    "# what if the positive word is preceded by a negation within 3 words in a sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
